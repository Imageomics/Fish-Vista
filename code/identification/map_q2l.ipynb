{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRun the q2l inference code. Use their map method to calculate map \\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Run the q2l inference code. Use their map method to calculate map \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os, sys\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "from typing import List\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/ksmehrab/FishDatasetTrack/Identification/Query2label/fish_q2l')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "server = 'arc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def voc_ap(rec, prec, true_num):\n",
    "    mrec = np.concatenate(([0.], rec, [1.]))\n",
    "    mpre = np.concatenate(([0.], prec, [0.]))\n",
    "    for i in range(mpre.size - 1, 0, -1):\n",
    "        mpre[i - 1] = np.maximum(mpre[i - 1], mpre[i])\n",
    "    i = np.where(mrec[1:] != mrec[:-1])[0]\n",
    "    ap = np.sum((mrec[i + 1] - mrec[i]) * mpre[i + 1])\n",
    "    return ap\n",
    "\n",
    "\n",
    "def voc_mAP(imagessetfilelist, num, return_each=False):\n",
    "    if isinstance(imagessetfilelist, str):\n",
    "        imagessetfilelist = [imagessetfilelist]\n",
    "    lines = []\n",
    "    for imagessetfile in imagessetfilelist:\n",
    "        with open(imagessetfile, 'r') as f:\n",
    "            lines.extend(f.readlines())\n",
    "    \n",
    "    seg = np.array([x.strip().split(' ') for x in lines]).astype(float)\n",
    "    gt_label = seg[:,num:].astype(np.int32)\n",
    "    num_target = np.sum(gt_label, axis=1, keepdims = True)\n",
    "\n",
    "\n",
    "    sample_num = len(gt_label)\n",
    "    class_num = num\n",
    "    tp = np.zeros(sample_num)\n",
    "    fp = np.zeros(sample_num)\n",
    "    aps = []\n",
    "\n",
    "    for class_id in range(class_num):\n",
    "        confidence = seg[:,class_id]\n",
    "        sorted_ind = np.argsort(-confidence)\n",
    "        sorted_scores = np.sort(-confidence)\n",
    "        sorted_label = [gt_label[x][class_id] for x in sorted_ind]\n",
    "\n",
    "        for i in range(sample_num):\n",
    "            tp[i] = (sorted_label[i]>0)\n",
    "            fp[i] = (sorted_label[i]<=0)\n",
    "        true_num = 0\n",
    "        true_num = sum(tp)\n",
    "        fp = np.cumsum(fp)\n",
    "        tp = np.cumsum(tp)\n",
    "        rec = tp / float(true_num)\n",
    "        prec = tp / np.maximum(tp + fp, np.finfo(np.float64).eps)\n",
    "        ap = voc_ap(rec, prec, true_num)\n",
    "        aps += [ap]\n",
    "\n",
    "    np.set_printoptions(precision=6, suppress=True)\n",
    "    aps = np.array(aps) * 100\n",
    "    mAP = np.mean(aps)\n",
    "    if return_each:\n",
    "        return mAP, aps\n",
    "    return mAP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def validate(val_loader, model, amp, num_class, output_path):\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "    saved_data = []\n",
    "    all_predicted = []\n",
    "    all_targets = []\n",
    "    with torch.no_grad():\n",
    "        for i, (images, target) in enumerate(tqdm(val_loader)):\n",
    "            images = images.cuda(non_blocking=True)\n",
    "            target = target.cuda(non_blocking=True)\n",
    "\n",
    "            # compute output\n",
    "            with torch.cuda.amp.autocast(enabled=amp):\n",
    "                output = model(images)\n",
    "                # breakpoint()\n",
    "                output_sm = nn.functional.sigmoid(output)\n",
    "                \n",
    "            # Flip the pelvic fin trait\n",
    "            output_sm = output_sm.detach().cpu()\n",
    "            target = target.detach().cpu()\n",
    "            \n",
    "            output_sm[:, 1] = 1 - output_sm[:, 1]\n",
    "            target[:, 1] = 1 - target[:, 1]\n",
    "            \n",
    "            all_predicted.append(output_sm.numpy())\n",
    "            all_targets.append(target.numpy())\n",
    "            \n",
    "            # save some data\n",
    "            _item = torch.cat((output_sm, target), 1)\n",
    "            saved_data.append(_item)\n",
    "        \n",
    "        all_predicted = np.vstack(all_predicted)\n",
    "        all_targets = np.vstack(all_targets)\n",
    "\n",
    "        # calculate mAP\n",
    "        saved_data = torch.cat(saved_data, 0).numpy()\n",
    "        saved_name = 'saved_data_tmp.txt'\n",
    "        np.savetxt(os.path.join(output_path, saved_name), saved_data)\n",
    "\n",
    "        print(\"Calculating mAP:\")\n",
    "        filenamelist = ['saved_data_tmp.txt']\n",
    "        metric_func = voc_mAP                \n",
    "        mAP, aps = metric_func([os.path.join(output_path, _filename) for _filename in filenamelist], num_class, return_each=True)\n",
    "       \n",
    "        ### SKLEARN MAP\n",
    "\n",
    "        # Calculate Average Precision for each class\n",
    "        sk_aps = []\n",
    "        for i in range(all_targets.shape[1]):\n",
    "            ap = average_precision_score(all_targets[:, i], all_predicted[:, i])\n",
    "            sk_aps.append(ap)\n",
    "\n",
    "        # Compute mAP\n",
    "        sk_mAP = np.mean(sk_aps)\n",
    "        \n",
    "    return aps, mAP, sk_aps, sk_mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp = True\n",
    "num_class = 4\n",
    "### CHANGE OUTPUT PATH HERE\n",
    "output = '/home/ksmehrab/FishDatasetTrack/Identification/TraitIDBasic/Outputs/results_swinb_wbce_basic'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# START LOADING MODEL AND DATA LOADER \n",
    "# Get model\n",
    "from model import get_custom_model\n",
    "\n",
    "#### CHANGE MODEL AND CHECKPOINT_PATH\n",
    "MODEL = 'swin_b'\n",
    "N_CLASSES = num_class\n",
    "\n",
    "\n",
    "model = get_custom_model(\n",
    "    model_name=MODEL,\n",
    "    num_classes=N_CLASSES,\n",
    "    pretrained=False\n",
    ")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get checkpoint\n",
    "checkpoint_path = '/home/ksmehrab/FishDatasetTrack/Identification/TraitIDBasic/Outputs/results_swinb_wbce_basic/ckpt_9229_S9229_tid_swinb_basic_fishair_processed_swin_b.t7'\n",
    "ckpt_t = torch.load(checkpoint_path)\n",
    "model.load_state_dict(ckpt_t['net'])\n",
    "epoch = ckpt_t['epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test loader\n",
    "from pathlib import Path\n",
    "if server == 'pda':\n",
    "#     train_file = Path('/data/DatasetTrackFinalData/Identification/trait_identification_train.csv')\n",
    "#     val_file = Path('/data/DatasetTrackFinalData/Identification/trait_identification_val.csv')\n",
    "    test_file = Path('/data/DatasetTrackFinalData/Identification/trait_identification_test_inspecies.csv')\n",
    "    lv_sp_normal_test_file = Path('/data/DatasetTrackFinalData/Identification/trait_identification_test_leavespecies.csv')\n",
    "    lv_sp_difficult_test_file = None\n",
    "    img_dir = Path('/data/BGRemovedCropped/all')\n",
    "elif server == 'arc':\n",
    "#     train_file = Path('/projects/ml4science/FishDatasetTrack/DatasetTrackFinalData/Identification/trait_identification_train.csv')\n",
    "#     val_file = Path('/projects/ml4science/FishDatasetTrack/DatasetTrackFinalData/Identification/trait_identification_val.csv')\n",
    "    test_file = Path('/projects/ml4science/FishDatasetTrack/DatasetTrackFinalData/Identification/trait_identification_test_inspecies.csv')\n",
    "    lv_sp_normal_test_file = Path('/projects/ml4science/FishDatasetTrack/DatasetTrackFinalData/Identification/trait_identification_test_leavespecies.csv')\n",
    "    lv_sp_difficult_test_file = Path('/projects/ml4science/FishDatasetTrack/DatasetTrackFinalData/Segmentation/annotations_mlic.csv')\n",
    "    img_dir = Path('/projects/ml4science/FishAIR/BGRemovedCropped/all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_setup import get_transform, get_dataset_and_dataloader\n",
    "\n",
    "mean = torch.tensor([0.9353, 0.9175, 0.8923])\n",
    "std = torch.tensor([0.1535, 0.1933, 0.2464])\n",
    "transform = get_transform(224, mean, std, 'squarepad_augment_normalize')\n",
    "test_transform = get_transform(224, mean, std, 'squarepad_no_augment_normalize')\n",
    "\n",
    "BATCH_SIZE=256\n",
    "num_workers = 8\n",
    "\n",
    "test_dataset, test_loader = get_dataset_and_dataloader(\n",
    "    data_file=test_file,\n",
    "    img_dir=img_dir,\n",
    "    transform=test_transform,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=num_workers\n",
    ")\n",
    "\n",
    "if lv_sp_normal_test_file:\n",
    "    lv_sp_normal_dataset, lv_sp_normal_loader = get_dataset_and_dataloader(\n",
    "        data_file=lv_sp_normal_test_file,\n",
    "        img_dir=img_dir,\n",
    "        transform=test_transform,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=num_workers\n",
    "    )\n",
    "\n",
    "if lv_sp_difficult_test_file:\n",
    "    lv_sp_dif_dataset, lv_sp_dif_loader = get_dataset_and_dataloader(\n",
    "        data_file=lv_sp_difficult_test_file,\n",
    "        img_dir=img_dir,\n",
    "        transform=test_transform,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        num_workers=num_workers\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/7 [00:00<?, ?it/s]/home/ksmehrab/.conda/envs/py39/lib/python3.9/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "100%|██████████| 7/7 [01:47<00:00, 15.40s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating mAP:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "q2l_aps, q2l_map, sk_aps, sk_map = validate(lv_sp_normal_loader, model, amp, num_class, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "q2l_aps:  [82.97406277947556, 39.74128396051576, 82.04788472937936, 44.67251751695641]\n",
      "q2l_map:62.358937246581775\n"
     ]
    }
   ],
   "source": [
    "print(f'q2l_aps:  {q2l_aps.tolist()}\\nq2l_map: {q2l_map}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sk_aps:  [0.8203605169115833, 0.39597167150629464, 0.8148718101808212, 0.42998019812404914]\n",
      "sk_map: 0.6152960491806871\n"
     ]
    }
   ],
   "source": [
    "print(f'sk_aps:  {sk_aps}\\nsk_map: {sk_map}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
